{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import HumanMessagePromptTemplate, SystemMessagePromptTemplate, ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from pprint import pprint\n",
    "import re\n",
    "from typing import List, Set, Optional\n",
    "from dataclasses import dataclass\n",
    "from difflib import SequenceMatcher\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from nltk.tokenize import TreebankWordTokenizer as twt\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://192.168.7.69:8080\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-qKGcKNQ6JqG2nYhsZSIlT3BlbrFJ7VYD1mqaqL7jMJqZ1nSF\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Document:\n",
    "    text: str\n",
    "\n",
    "\n",
    "@dataclass()\n",
    "class Annotation:\n",
    "    start: int\n",
    "    end: int\n",
    "    label: str\n",
    "    text: Optional[str] = None\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.start, self.end, self.label))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AnnotatedDocument(Document):\n",
    "    annotations: Set[Annotation]\n",
    "\n",
    "\n",
    "def conll_to_inline_annotated_string(conll):\n",
    "    inline_annotated_document = \"\"\n",
    "    current_label = None\n",
    "    for token, label in conll:\n",
    "        if label == \"O\":\n",
    "            if not current_label:\n",
    "                inline_annotated_document += f\"{token} \"\n",
    "            else:\n",
    "                inline_annotated_document += f\"</{current_label}> {token} \"\n",
    "                current_label = None\n",
    "        else:\n",
    "            current_label = label.split(\"-\")[1]\n",
    "            inline_annotated_document += f\"<{current_label}>{token}\"\n",
    "    return inline_annotated_document.strip()\n",
    "\n",
    "\n",
    "def annotated_document_to_conll(annotated_document: AnnotatedDocument) -> List[str]:\n",
    "    spans = list(twt().span_tokenize(annotated_document.text))\n",
    "    tokens = [annotated_document.text[span[0] : span[1]] for span in spans]\n",
    "    boundaries = [span[0] for span in spans]\n",
    "    conll = [\"O\"] * len(spans)\n",
    "    for annotation in annotated_document.annotations:\n",
    "        start = annotation.start\n",
    "        end = annotation.end\n",
    "        label = annotation.label\n",
    "        start_idx = 0\n",
    "        for i, boundary in enumerate(boundaries):\n",
    "            if start == boundary:\n",
    "                start_idx = i\n",
    "                break\n",
    "            elif start < boundary:\n",
    "                start_idx = i\n",
    "                break\n",
    "        end_idx = start_idx\n",
    "        for i, boundary in list(enumerate(boundaries))[start_idx + 1 :]:\n",
    "            if end == boundary:\n",
    "                end_idx = i - 1\n",
    "                break\n",
    "            elif end < boundary:\n",
    "                end_idx = i - 1\n",
    "                break\n",
    "        for i in range(start_idx, end_idx + 1):\n",
    "            if i == start_idx:\n",
    "                conll[i] = f\"B-{label}\"\n",
    "            else:\n",
    "                conll[i] = f\"I-{label}\"\n",
    "    return list(zip(tokens, conll))\n",
    "\n",
    "\n",
    "def annotated_document_to_inline_annotated_string(annotated_document):\n",
    "    annotated_document = deepcopy(annotated_document)\n",
    "    inline_annotated_string = annotated_document.text\n",
    "    annotations = sorted(annotated_document.annotations, key=lambda x: x.start)\n",
    "    for i in range(len(annotations)):\n",
    "        annotation = annotations[i]\n",
    "        start = annotation.start\n",
    "        end = annotation.end\n",
    "        label = annotation.label\n",
    "        text = annotation.text\n",
    "        inline_annotation = f\"<{label}>{text}</{label}>\"\n",
    "        inline_annotated_string = (\n",
    "            inline_annotated_string[:start]\n",
    "            + inline_annotation\n",
    "            + inline_annotated_string[end:]\n",
    "        )\n",
    "        for j in range(i, len(annotations)):\n",
    "            annotations[j].start += len(inline_annotation) - len(text)\n",
    "            annotations[j].end += len(inline_annotation) - len(text)\n",
    "\n",
    "    return inline_annotated_string\n",
    "\n",
    "\n",
    "def extract_gpt_annotation(\n",
    "    annotated_text: str, entity_set: List[str]\n",
    ") -> AnnotatedDocument:\n",
    "    annotations = set()\n",
    "    offset = 0\n",
    "    entities_pattern = [rf\"<(.*?)>(.*?)</(.*?)>\"]\n",
    "    all_matches = [\n",
    "        re.finditer(entity_pattern, annotated_text)\n",
    "        for entity_pattern in entities_pattern\n",
    "    ]\n",
    "    all_matches = [match for matches in all_matches for match in matches]\n",
    "    # sort all matches by start position in order to change the offset correctly\n",
    "    all_matches = sorted(all_matches, key=lambda x: x.start())\n",
    "    for match in all_matches:\n",
    "        match_offset = len(match.group(0)) - len(match.group(2))\n",
    "        start = match.start() - offset\n",
    "        end = match.end() - offset - match_offset\n",
    "        offset += match_offset\n",
    "        # getting the entity name\n",
    "        entity_name = match.group(1)\n",
    "        # add the entity to the dictionary like this: {entity_name: [ [named_entity,start, end], [named_entity, start, end] , ...]}\n",
    "        if entity_name in entity_set:\n",
    "            annotations.add(Annotation(start, end, entity_name, text=match.group(2)))\n",
    "    for match in all_matches:\n",
    "        annotated_text = annotated_text.replace(match.group(0), match.group(2))\n",
    "    annotated_document = AnnotatedDocument(text=annotated_text, annotations=annotations)\n",
    "    return annotated_document\n",
    "\n",
    "\n",
    "def align_annotation(\n",
    "    original_text: str, chatgpt_annotated_document: AnnotatedDocument\n",
    ") -> AnnotatedDocument:\n",
    "    fixed_annotation = deepcopy(chatgpt_annotated_document)\n",
    "    a = chatgpt_annotated_document.text\n",
    "    b = original_text\n",
    "\n",
    "    total_difs = [\n",
    "        (tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2])\n",
    "        for tag, i1, i2, j1, j2 in SequenceMatcher(None, a, b).get_opcodes()\n",
    "    ]\n",
    "\n",
    "    replace_difs = [dif for dif in total_difs if dif[0] == \"replace\"]\n",
    "\n",
    "    # fix the replace difs\n",
    "    for dif in replace_difs:\n",
    "        a = dif[5]\n",
    "        b = dif[6]\n",
    "        new_entity_difs = [\n",
    "            (\n",
    "                tag,\n",
    "                i1 + dif[1],\n",
    "                i2 + dif[1],\n",
    "                j1 + dif[3],\n",
    "                j2 + dif[3],\n",
    "                a[i1:i2],\n",
    "                b[j1:j2],\n",
    "            )\n",
    "            for tag, i1, i2, j1, j2 in SequenceMatcher(None, a, b).get_opcodes()\n",
    "        ]\n",
    "        total_difs.remove(dif)\n",
    "        total_difs += new_entity_difs\n",
    "\n",
    "    for entity in fixed_annotation.annotations:\n",
    "        difs = [dif for dif in total_difs if dif[1] <= entity.start]\n",
    "        offset = sum([(dif[4] - dif[3]) - (dif[2] - dif[1]) for dif in difs])\n",
    "        entity.start += offset\n",
    "        entity.end += offset\n",
    "\n",
    "    fixed_annotation.text = original_text\n",
    "\n",
    "    # remove annotations that not exist in original text\n",
    "    # because gpt adds or modifies text\n",
    "\n",
    "    fixed_annotations_2 = list(fixed_annotation.annotations)\n",
    "\n",
    "    for annotation in fixed_annotations_2.copy():\n",
    "        if (\n",
    "            (annotation.text not in original_text)\n",
    "            | (annotation.start < 0)\n",
    "            | (annotation.end < 0)\n",
    "        ):\n",
    "            fixed_annotations_2.remove(annotation)\n",
    "\n",
    "    fixed_annotation.annotations = set(fixed_annotations_2)\n",
    "\n",
    "    return fixed_annotation\n",
    "\n",
    "\n",
    "def dict_to_enumeration(d):\n",
    "    enumeration = \"\"\n",
    "    for key, value in d.items():\n",
    "        enumeration += f\"- {key}: {value}\\n\"\n",
    "    return enumeration.strip()\n",
    "\n",
    "\n",
    "class IclModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        max_tokens=256,\n",
    "        stop=[\"###\"],\n",
    "    ):\n",
    "        self.max_tokens = max_tokens\n",
    "        self.stop = stop\n",
    "        self.model = model\n",
    "\n",
    "    def query_model(self, messages):\n",
    "        chat = ChatOpenAI(\n",
    "            model_name=self.model,\n",
    "            max_tokens=self.max_tokens,\n",
    "            model_kwargs={\"presence_penalty\": 0},\n",
    "        )\n",
    "        return chat(messages, stop=self.stop)\n",
    "\n",
    "\n",
    "class IclNer(IclModel):\n",
    "    def contextualize(self, prompt_template, entities):\n",
    "        self.entities = entities\n",
    "        self.system_message = SystemMessagePromptTemplate.from_template(\n",
    "            prompt_template\n",
    "        ).format(\n",
    "            entities=dict_to_enumeration(entities), entity_list=list(entities.keys())\n",
    "        )\n",
    "        self.chat_template = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessagePromptTemplate.from_template(\"{x}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def predict(self, x):\n",
    "        messages = self.chat_template.format_messages(x=x)\n",
    "        completion = self.query_model(messages)\n",
    "        annotated_document = extract_gpt_annotation(\n",
    "            completion.content, self.entities.keys()\n",
    "        )\n",
    "        aligned_annotated_document = align_annotation(x, annotated_document)\n",
    "        y = aligned_annotated_document\n",
    "        return y\n",
    "\n",
    "\n",
    "class IclFewShotNer(IclNer):\n",
    "    def contextualize(self, prompt_template, entities, examples):\n",
    "        self.entities = entities\n",
    "        self.system_message = SystemMessagePromptTemplate.from_template(\n",
    "            prompt_template\n",
    "        ).format(\n",
    "            entities=dict_to_enumeration(entities), entity_list=list(entities.keys())\n",
    "        )\n",
    "        example_template = ChatPromptTemplate.from_messages(\n",
    "            [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
    "        )\n",
    "        few_shot_template = FewShotChatMessagePromptTemplate(\n",
    "            examples=examples,\n",
    "            example_prompt=example_template,\n",
    "        )\n",
    "        self.chat_template = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                self.system_message,\n",
    "                few_shot_template,\n",
    "                HumanMessagePromptTemplate.from_template(\"{x}\"),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatedDocument(text='Pedro Pereira is the president of Perú and the owner '\n",
      "                       'of Walmart.',\n",
      "                  annotations={Annotation(start=56,\n",
      "                                          end=63,\n",
      "                                          label='organization',\n",
      "                                          text='Walmart'),\n",
      "                               Annotation(start=34,\n",
      "                                          end=38,\n",
      "                                          label='location',\n",
      "                                          text='Perú')})\n",
      "AnnotatedDocument(text='Pedro Pereira is the president of Perú and the owner '\n",
      "                       'of Walmart.',\n",
      "                  annotations={Annotation(start=34,\n",
      "                                          end=38,\n",
      "                                          label='location',\n",
      "                                          text='Perú'),\n",
      "                               Annotation(start=56,\n",
      "                                          end=63,\n",
      "                                          label='organization',\n",
      "                                          text='Walmart')})\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"You are a named entity recognizer that must detect the next entities: \n",
    "{entities} \n",
    "You must answer with the same input text, but with the named entities annotated with in-line tags, where each tag corresponds to an entity name, for example: <name>John Doe</name> is the owner of <organization>ACME</organization>.\n",
    "The only available tags are: {entity_list}, you cannot add more tags than the included in that list.\n",
    "IMPORTANT: YOU SHOULD NOT CHANGE THE INPUT TEXT, ONLY ADD THE TAGS.\"\"\"\n",
    "\n",
    "entities = {\n",
    "    \"person\": \"A person name, it can include first and last names, for example: John Kennedy and Bill Gates\",\n",
    "    \"organization\": \"An organization name, it can be a company, a government agency, etc.\",\n",
    "    \"location\": \"A location name, it can be a city, a country, etc.\",\n",
    "}\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Gabriel Boric is the president of Chile\",\n",
    "        \"output\": \"<person>Gabriel Boric</person> is the president of <location>Chile</location>\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Elon Musk is the owner of the US company Tesla\",\n",
    "        \"output\": \"<person>Elon Musk</person> is the owner of the <location>US</location> company <organization>Tesla</organization>\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Bill Gates is the owner of Microsoft\",\n",
    "        \"output\": \"<person>Bill Gates</person> is the owner of <organization>Microsoft</organization>\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"John is the president of Argentina\",\n",
    "        \"output\": \"<person>John</person> is the president of <location>Argentina</location>\",\n",
    "    },\n",
    "]\n",
    "\n",
    "x = \"Pedro Pereira is the president of Perú and the owner of Walmart.\"\n",
    "\n",
    "model = IclNer()\n",
    "model.contextualize(prompt_template=prompt_template, entities=entities)\n",
    "annotated_document = model.predict(x)\n",
    "pprint(annotated_document)\n",
    "\n",
    "model2 = IclFewShotNer()\n",
    "model2.contextualize(\n",
    "    prompt_template=prompt_template, entities=entities, examples=examples\n",
    ")\n",
    "annotated_document2 = model2.predict(x)\n",
    "pprint(annotated_document2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
